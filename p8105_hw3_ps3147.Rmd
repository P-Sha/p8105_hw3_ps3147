---
title: "homework 3"
author: Purnima Sharma
date: "October 6, 2020"
output: github_document
---

```{r setup, include = FALSE}
library(tidyverse)
library(p8105.datasets)
library(patchwork)

knitr::opts_chunk$set(
  fig.width = 6,
  fig.asp = .6,          
  out.width = "90%"      
)
theme_set(theme_minimal() + theme(legend.position = "bottom"))

options(
  ggplot2.continuous.colour = "viridis", # to override ggplot default colors.
  ggplot2.continuous.fill = "viridis"
)

scale_colour_discrete = scale_colour_viridis_d
scale_fill_discrete = scale_fill_viridis_d
```

## Problem 1

```{r load data}
data("instacart")
```

This dataset contains `r nrow(instacart)` rows and `r ncol(instacart)` columns.

Observations are the level of items in orders by a user. There are user / order variables: user ID, order ID, order day, and order hour. There are also item variables: name, aisle, department, and some numeric codes. 

How many aisles, and which are most items from?

```{r}
instacart %>% 
  count(aisle) %>% 
  arrange(desc(n))
```

Plot of #of items in each aisle, for aisles with more than 10,000 items.

```{r}
instacart %>% 
  count(aisle) %>%
  filter(n > 10000) %>%
  mutate(
    aisle = factor(aisle),
    aisle = fct_reorder(aisle, n)
  ) %>% 
  ggplot(aes(x = aisle, y = n)) +
  geom_point() +
  theme(axis.text.x = element_text(angle = 60, vjust = 0.5, hjust = 1))
```

Table of 3 most popular items in given aisles.

```{r}
instacart %>% 
  filter(aisle %in% c("baking ingredients", "dog food care", "packaged vegetables fruits" )) %>% 
   group_by(aisle) %>% 
  count(product_name) %>% 
   mutate(rank = min_rank(desc(n))) %>% 
  filter(rank < 4) %>% 
  arrange(aisle, rank) %>% 
  knitr::kable()
```

Table of mean hour of the day for order of given two products:Apples vs ice cream

```{r}
instacart %>% 
  filter(product_name %in% c("Pink Lady Apples", "Coffee Ice Cream")) %>% 
  group_by(product_name, order_dow) %>% 
  summarize(mean_hour = mean(order_hour_of_day)) %>% 
  pivot_wider(
    names_from = order_dow,
    values_from = mean_hour
  )
```

## Problem 2

Read and tidy the accelerometer data.

```{r}
accel_df = 
  read_csv("./data/accel_data.csv") %>% 
   pivot_longer(
    activity.1:activity.1440,
    names_to = "min_of_the_day",
    names_prefix = "activity.",
    values_to = "activity_count"
  )  %>% 
  mutate(
    min_of_the_day = as.numeric(min_of_the_day),
    day = factor(day)
  ) %>% 
  mutate(
  day_type = recode(day,"Saturday" = "weekend", "Sunday" = "weekend", "Monday" = "weekday", "Tuesday" = "weekday","Wednesday" = "weekday","Thursday" = "weekday","Friday" = "weekday")
  )
accel_df =
   mutate(accel_df,
   day = fct_relevel(day, "Sunday", "Monday", "Tuesday", "Wednesday", "Thursday", "Friday", "Saturday"))
```

This dataset based on "accelerometer data" contains `r nrow(accel_df)` rows and `r ncol(accel_df)` columns. The dataset consists information on 5 weeks of recorded activity counts based on an accelerometer activity, by the minute of each day. The activity count ranges from `r summarise(accel_df, min(activity_count))` to `r summarise(accel_df, max(activity_count))`.

Table of activity per day.

```{r}
accel_df %>%
  group_by(week, day) %>% 
    summarize(total_daily_activity = sum(activity_count)) %>% 
  pivot_wider(
    names_from = "day",
    values_from = "total_daily_activity"
  )
```

There seems to be least activity on Saturdays in weeks 4 and 5. Middle of the weeks on Tuesdays through Thursdays showed the most consistent high activity counts.

Graph of 24-hr activity for each day.

```{r}
accel_df %>% 
   group_by(day_id) %>% 
  ggplot(aes(x = min_of_the_day, y = activity_count, color = day)) + 
  geom_line(alpha = .4) + 
  labs(
    title = "Activity plot",
    x = "Minutes of the day",
    y = "Activity count"
     ) +
  geom_smooth(aes(group = day), se = FALSE)
  theme(legend.position = "bottom")
```

The graphs seems fairly consistent in pattern for all given days in a week. Starting at 0 min, indicating midnight, there seems to be minimal activity count up to roughly 6- 7am. Activity seems to peak in the morning hours, and the again late in the evening. There were a few days with more daytime activity tha usual.


## Problem 3

Read "NY NOAA" data

```{r}
data("ny_noaa")
```

This weather related data is from the National Oceanic and Atmospheric Association (NOAA). The data consists of `r nrow(ny_noaa)` rows of observations on `r ncol(ny_noaa)` variables. It is organized by weather stations, listed by their ID numbers. Each station has data for precipitation, snow, depth of snow, maximum and minimum temperatures for various years, although many of these records are missing since stations are not required to collect information on all variables. These large amounts of missing data could make comparisons and other summary tasks challenging. 

Tidy data.

```{r}
month_df = 
  tibble(
    month = 1:12,
    month_name = month.name
  ) 
month_df = mutate(month_df, month = as.character(month))

noaa_df = 
ny_noaa %>% 
   separate(date, into = c("year", "month", "day"), convert = TRUE) %>% 
   mutate(
     month = as.character(month),
     tmin = as.numeric(tmin),
     tmax = as.numeric(tmax),
     tmin = tmin / 10,            
     tmax = tmax / 10
    )

noaa_df =
   left_join(noaa_df, month_df, by = "month") %>% 
   mutate(month = month_name) %>% 
   select(-month_name)
```

Most commonly observed values for snowfall.
```{r}
noaa_df %>% 
  na.omit() %>%  
  count(snow) %>%  
  arrange(desc(n)) %>% 
  mutate(
    rank = min_rank(desc(n))
  ) %>% 
  filter(rank < 4)
```

 Highest value of 0 mm snowfall being records of snow during summer and other non-snow months in NY, followed by 25mm and then 13mm of recorded snowfall. 

Two-panel plot.

```{r}
noaa_df %>%
   filter(month %in% c("January", "July")) %>% 
  group_by(id, year, month) %>% 
  drop_na(tmax) %>% 
   mutate(
    mean_tmax = mean(tmax)) %>% 
  ggplot(aes(x = year, y = mean_tmax, group = id, color = id)) +
  geom_point() +
  geom_path() +
  facet_grid(.~ month) +
  labs(title = "average maximum temperatures for January and July", x = "year", y = "average maximum temperature (C)") +
  theme(legend.position = "none")
```

The plot shows distinct difference between the average maximum temperatures in January and July over all the weather stations, every year. As expected ,average temperature in January was much lower than in July. Other than the two colder than usual recording in January of early 1980's and 2005, and again in two different years in July, the temperatures were fairly consistent between a certain range. 

Plot: tmax vs tmin, and yearly snowfall.

```{r}
tmax_tmin_plot =
noaa_df %>%
  ggplot(aes(x = tmin, y = tmax, color = id)) + 
  geom_boxplot() +
  labs(title = "maximum versus minimum recorded temperatures", x = "minimum temperatures (C)", y = "maximum temperatures (C)") +
   theme(legend.position = "none")

snowfall_plot = 
  noaa_df %>%
  group_by(year) %>% 
   filter(snow > 0) %>%
  filter(snow < 100) %>%
  ggplot(aes(x = year, y = snow, color = year)) + 
  geom_boxplot() + 
  labs(title = "Yearly snowfall", x = "Year", y = "snowfall (mm)") +
  theme(legend.position = "none")
  
tmax_tmin_plot / snowfall_plot

```






