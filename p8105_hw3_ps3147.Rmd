---
title: "homework 3"
author: Purnima Sharma
date: "October 6, 2020"
output: github_document
---

```{r setup, include = FALSE}
library(tidyverse)
library(p8105.datasets)

knitr::opts_chunk$set(
  fig.width = 6,
  fig.asp = .6,          
  out.width = "90%"      
)
theme_set(theme_minimal() + theme(legend.position = "bottom"))

options(
  ggplot2.continuous.colour = "viridis", # to override ggplot default colors.
  ggplot2.continuous.fill = "viridis"
)

scale_colour_discrete = scale_colour_viridis_d
scale_fill_discrete = scale_fill_viridis_d
```

## Problem 1

```{r load data}
data("instacart")
```

This dataset contains `r nrow(instacart)` rows and `r ncol(instacart)` columns.

Observations are the level of items in orders by a user. There are user / order variables: user ID, order ID, order day, and order hour. There are also item variables: name, aisle, department, and some numeric codes. 

How many aisles, and which are most items from?

```{r}
instacart %>% 
  count(aisle) %>% 
  arrange(desc(n))
```

Plot of #of items in each aisle, for aisles with more than 10,000 items.

```{r}
instacart %>% 
  count(aisle) %>%
  filter(n > 10000) %>%
  mutate(
    aisle = factor(aisle),
    aisle = fct_reorder(aisle, n)
  ) %>% 
  ggplot(aes(x = aisle, y = n)) +
  geom_point() +
  theme(axis.text.x = element_text(angle = 60, vjust = 0.5, hjust = 1))
```

Table of 3 most popular items in given aisles.

```{r}
instacart %>% 
  filter(aisle %in% c("baking ingredients", "dog food care", "packaged vegetables fruits" )) %>% 
   group_by(aisle) %>% 
  count(product_name) %>% 
   mutate(rank = min_rank(desc(n))) %>% 
  filter(rank < 4) %>% 
  arrange(aisle, rank) %>% 
  knitr::kable()
```

Table of mean hour of the day for order of given two products:Apples vs ice cream

```{r}
instacart %>% 
  filter(product_name %in% c("Pink Lady Apples", "Coffee Ice Cream")) %>% 
  group_by(product_name, order_dow) %>% 
  summarize(mean_hour = mean(order_hour_of_day)) %>% 
  pivot_wider(
    names_from = order_dow,
    values_from = mean_hour
  )
```

## Problem 2

Read and tidy the accelerometer data.

```{r}
accel_df = 
  read_csv("./data/accel_data.csv") %>% 
   pivot_longer(
    activity.1:activity.1440,
    names_to = "min_of_the_day",
    names_prefix = "activity.",
    values_to = "activity_count"
  )  %>% 
  mutate(
    min_of_the_day = as.numeric(min_of_the_day),
    day = factor(day)
  ) %>% 
  mutate(
  day_type = recode(day,"Saturday" = "weekend", "Sunday" = "weekend", "Monday" = "weekday", "Tuesday" = "weekday","Wednesday" = "weekday","Thursday" = "weekday","Friday" = "weekday")
  )
```

This dataset based on "accelerometer data" contains `r nrow(accel_df)` rows and `r ncol(accel_df)` columns. The dataset consists information on 5 weeks of recorded activity counts based on an accelerometer activity, by the minute of each day. The activity count ranges from `r summarise(accel_df, min(activity_count))` to `r summarise(accel_df, max(activity_count))`.

Table of activity per day.

```{r}
accel_df %>%
 ## day = fct_reorder(day)##
  group_by(week, day) %>% 
    summarize(total_daily_activity = sum(activity_count)) %>% 
  pivot_wider(
    names_from = "day",
    values_from = "total_daily_activity"
  )
```

There seems to be least activity on Saturdays in weeks 4 and 5. Middle of the weeks on Tuesdays through Thursdays showed the most consistent high activity counts.

Graph of 24-hr activity for each day.

```{r}
accel_df %>% 
  group_by(day_id) %>% 
  ggplot(aes(x = min_of_the_day, y = activity_count, color = day)) + 
  geom_line(alpha = .5) + 
  labs(
    title = "Activity plot",
    x = "Minutes of the day",
    y = "Activity count"
     ) +
  theme(legend.position = "bottom")
```

The graphs seems fairly consistent in pattern for all given days in a week. Starting at 0 min, indicating midnight, there seems to be minimal activity count up to roughly 6- 7am. Activity seems to peak in the morning hours, and the again late in the evening. There were a few days with more daytime activity tha usual.


## Problem 3






